{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd7b482-6931-4ba7-9c86-b2cc3b483452",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install telethon git+https://github.com/dontbeidle/kaalin-python.git --quiet\n",
    "\n",
    "import re, asyncio, nest_asyncio, pandas as pd, os\n",
    "from telethon import TelegramClient\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from kaalin.converter import cyrillic2latin\n",
    "\n",
    "api_id = ***\n",
    "api_hash = ***\n",
    "phone = ***\n",
    "channel_username = \"paziyletuz\"\n",
    "fetch_limit = 10000\n",
    "target_sentences = 400\n",
    "\n",
    "\n",
    "cyr_raw = \"Karakalpak_Cyrillic_400.txt\"\n",
    "lat_raw = \"Karakalpak_Latin_400.txt\"\n",
    "cyr_clean = \"Karakalpak_Cyrillic_400_CLEAN.txt\"\n",
    "lat_clean = \"Karakalpak_Latin_400_CLEAN.txt\"\n",
    "\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F700-\\U0001F77F\"\n",
    "        \"\\U0001F780-\\U0001F7FF\"\n",
    "        \"\\U0001F800-\\U0001F8FF\"\n",
    "        \"\\U0001F900-\\U0001F9FF\"\n",
    "        \"\\U0001FA00-\\U0001FAFF\"\n",
    "        \"\\U0001FB00-\\U0001FBFF\"\n",
    "        \"\\u2600-\\u26FF\"\n",
    "        \"\\u2700-\\u27BF\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(\"\", text)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    text = remove_emojis(text)\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"(@\\w+)|#\\w+\", \"\", text)\n",
    "    bad_words = [\"instagram\", \"telegram\", \"facebook\", \"youtube\", \n",
    "                 \"obuna\", \"–ø–æ–¥–ø–∏—Å\", \"follow\", \".uz\", \".en\", \".kr\", \"t.me\"]\n",
    "    for w in bad_words:\n",
    "        text = re.sub(w, \"\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    if len(text.split()) < 3:\n",
    "        return None\n",
    "    return text\n",
    "\n",
    "\n",
    "async def fetch_messages():\n",
    "    client = TelegramClient(\"karakalpak_session\", api_id, api_hash)\n",
    "    await client.start(phone)\n",
    "    print(f\"‚úÖ Signed in successfully as {phone}\")\n",
    "    print(f\"üì• Fetching messages from @{channel_username} ...\")\n",
    "\n",
    "    messages, offset_id = [], 0\n",
    "\n",
    "    while len(messages) < fetch_limit:\n",
    "        history = await client(GetHistoryRequest(\n",
    "            peer=channel_username,\n",
    "            offset_id=offset_id,\n",
    "            offset_date=None,\n",
    "            add_offset=0,\n",
    "            limit=100,\n",
    "            max_id=0,\n",
    "            min_id=0,\n",
    "            hash=0\n",
    "        ))\n",
    "        if not history.messages:\n",
    "            break\n",
    "\n",
    "        for message in history.messages:\n",
    "            if message.message:\n",
    "                clean_msg = clean_text(message.message)\n",
    "                if clean_msg:\n",
    "                    messages.append(clean_msg)\n",
    "            if len(messages) >= fetch_limit:\n",
    "                break\n",
    "\n",
    "        offset_id = history.messages[-1].id\n",
    "\n",
    "        if len(messages) >= fetch_limit:\n",
    "            break\n",
    "\n",
    "    await client.disconnect()\n",
    "    return messages\n",
    "\n",
    "\n",
    "def clean_file(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [l.strip() for l in f if l.strip()]\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        line = remove_emojis(line)\n",
    "        line = re.sub(r\"[¬´¬ª‚Äú‚Äù\\\"'‚Äô‚Ä¢‚Äî‚Äì‚Ä¶]\", \"\", line)\n",
    "        line = re.sub(r\"\\s+\", \" \", line).strip()\n",
    "        if len(line.split()) >= 4:\n",
    "            cleaned.append(line)\n",
    "    cleaned = list(dict.fromkeys(cleaned))[:target_sentences]\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(cleaned))\n",
    "    print(f\"‚úÖ Saved {len(cleaned)} lines ‚Üí {output_path}\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    msgs = await fetch_messages()\n",
    "    print(f\"Fetched {len(msgs)} messages total.\")\n",
    "\n",
    "    pd.Series(msgs).to_csv(cyr_raw, index=False, header=False, encoding=\"utf-8\")\n",
    "    print(f\"üíæ Saved raw Cyrillic ‚Üí {cyr_raw}\")\n",
    "\n",
    "    converted = [cyrillic2latin(line) for line in msgs]\n",
    "    pd.Series(converted).to_csv(lat_raw, index=False, header=False, encoding=\"utf-8\")\n",
    "    print(f\"üíæ Saved raw Latin ‚Üí {lat_raw}\")\n",
    "\n",
    "    clean_file(cyr_raw, cyr_clean)\n",
    "    clean_file(lat_raw, lat_clean)\n",
    "    print(\"üéâ DONE. Final cleaned dataset saved.\")\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "try:\n",
    "    asyncio.get_running_loop()\n",
    "except RuntimeError:\n",
    "    asyncio.run(main())\n",
    "else:\n",
    "    await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
